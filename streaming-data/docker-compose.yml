services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    platform: linux/arm64
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports: ["2181:2181"]
    networks: [data-pipeline-net]
    restart: unless-stopped

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    platform: linux/arm64
    container_name: kafka
    depends_on:
      - zookeeper
    ports: ["9092:9092"]
    environment:
      KAFKA_LOG_RETENTION_MS: 259200000
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_LOG_CLEANUP_POLICY: delete
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server kafka:9092 --list"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks: [data-pipeline-net]
    restart: unless-stopped

  kafka-connect:
    build:
      context: ./kafka
    container_name: kafka-connect
    depends_on:
      kafka:
        condition: service_healthy
      clickhouse-server:
        condition: service_healthy
    ports: ["8083:8083"]
    environment:
      BOOTSTRAP_SERVERS: 'kafka:9092'
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: 'kafka-connect-group'
      CONFIG_STORAGE_TOPIC: 'connect_configs'
      OFFSET_STORAGE_TOPIC: 'connect_offsets'
      STATUS_STORAGE_TOPIC: 'connect_status'
      CONNECT_KEY_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_VALUE_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_INTERNAL_KEY_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_INTERNAL_VALUE_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: 'false'
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: 'false'
    networks: [data-pipeline-net]
    restart: unless-stopped

  spark:
    image: jupyter/pyspark-notebook:spark-3.4.1
    platform: linux/arm64
    container_name: pyspark-transformer
    ports:
      - "4040:4040"
      - "8888:8888"
    environment:
      - JOB=all
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - RESERVASI_SOURCE_TOPIC=postgres_server.public.reservation_raw
      - RESERVASI_SINK_TOPIC=reservations_transformed
      - RESERVASI_CHECKPOINT=/tmp/spark_checkpoints/reservasi
      - PROFILE_SOURCE_TOPIC=postgres_server.public.profile_guest_raw
      - PROFILE_SINK_TOPIC=profile_guest_transformed
      - PROFILE_CHECKPOINT=/tmp/spark_checkpoints/profile_guest
      - CHAT_WHATSAPP_SOURCE_TOPIC=postgres_server.public.chat_whatsapp_raw
      - CHAT_WHATSAPP_SINK_TOPIC=chat_whatsapp_transformed
      - CHAT_WHATSAPP_CHECKPOINT=/tmp/spark_checkpoints/chat_whatsapp
      - TRANSACTION_RESTO_SOURCE_TOPIC=postgres_server.public.transaction_resto_raw
      - TRANSACTION_RESTO_SINK_TOPIC=transaction_resto_transformed
      - TRANSACTION_RESTO_CHECKPOINT=/tmp/spark_checkpoints/transaction_resto
    depends_on:
      kafka:
        condition: service_healthy 
    volumes:
      - ./spark_apps:/home/jovyan/work
    command: sh -c "echo 'Waiting 45 seconds for Kafka...' && sleep 45 && spark-submit --master 'local[*]' --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1 --py-files /home/jovyan/work/transform_reservasi.py,/home/jovyan/work/transform_profile_guest.py,/home/jovyan/work/transform_chat_whatsapp.py,/home/jovyan/work/transform_transaction_resto.py /home/jovyan/work/main.py 2>&1"
    networks: [data-pipeline-net]

  clickhouse-server:
    image: clickhouse/clickhouse-server:24.8
    container_name: clickhouse-sink-db
    ports:
      - "8123:8123"
      - "9005:9000"
    environment:
      - CLICKHOUSE_PASSWORD=password123
    volumes:
      - clickhouse_data:/var/lib/clickhouse/
    healthcheck:
      test: ["CMD", "wget", "-q", "-O-", "http://localhost:8123/ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks: [data-pipeline-net]
    restart: unless-stopped

volumes:
  clickhouse_data:

networks:
  data-pipeline-net:
    driver: bridge